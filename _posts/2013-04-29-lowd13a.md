---
pdf: http://proceedings.mlr.press/v31/lowd13a.pdf
title: Learning Markov Networks With Arithmetic Circuits
abstract: 'Markov networks are an effective way to represent complex probability distributions.  However,
  learning their structure and parameters or using them to answer queries is typically
  intractable.  One approach to making learning and inference tractable is to use
  approximations, such as pseudo-likelihood or approximate inference.  An alternate
  approach is to use a restricted class of models where exact inference is always
  efficient.  Previous work has explored low treewidth models, models with tree-structured
  features, and latent variable models.  In this paper, we introduce ACMN, the first
  ever method for learning efficient Markov networks with arbitrary conjunctive features.  The
  secret to ACMNâ€™s greater flexibility is its use of arithmetic circuits, a linear-time
  inference representation that can handle many high treewidth models by exploiting
  local structure.  ACMN uses the size of the corresponding arithmetic circuit as
  a learning bias, allowing it to trade off accuracy and inference complexity.  In
  experiments on 12 standard datasets, the tractable models learned by ACMN are more
  accurate than both tractable models learned by other algorithms and approximate
  inference in intractable models. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lowd13a
month: 0
tex_title: Learning Markov Networks With Arithmetic Circuits
firstpage: 406
lastpage: 414
page: 406-414
sections: 
author:
- given: Daniel
  family: Lowd
- given: Amirmohammad
  family: Rooshenas
date: 2013-04-29
address: Scottsdale, Arizona, USA
publisher: PMLR
container-title: Proceedings of the Sixteenth International Conference on Artificial
  Intelligence and Statistics
volume: '31'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 4
  - 29
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
