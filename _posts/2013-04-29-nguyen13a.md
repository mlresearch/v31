---
pdf: http://proceedings.mlr.press/v31/nguyen13a/nguyen13a.pdf
title: Competing with an Infinite Set of Models in Reinforcement Learning
abstract: We consider a reinforcement learning setting where the learner also has
  to deal with the problem of finding a suitable state-representation function from
  a given set of models. This has to be done while interacting with the environment
  in an online fashion (no resets), and the goal is to have small regret with respect
  to any Markov model in the set. For this setting, recently the BLB algorithm has
  been proposed, which achieves regret of order T^2/3, provided that the given set
  of models is finite. Our first contribution is to extend this result to a countably
  infinite set of models. Moreover, the BLB regret bound suffers from an additive
  term that can be exponential in the diameter of the MDP involved, since the diameter
  has to be guessed. The algorithm we propose avoids  guessing the diameter, thus
  improving the regret bound.
layout: inproceedings
id: nguyen13a
month: 0
firstpage: 463
lastpage: 471
page: 463-471
sections: 
author:
- given: Phuong
  family: Nguyen
- given: Odalric-Ambrym
  family: Maillard
- given: Daniil
  family: Ryabko
- given: Ronald
  family: Ortner
date: 2013-04-29
address: Scottsdale, Arizona, USA
publisher: PMLR
container-title: Proceedings of the Sixteenth International Conference on Artificial
  Intelligence and Statistics
volume: '31'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 4
  - 29
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
