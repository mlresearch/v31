---
pdf: http://proceedings.mlr.press/v31/gu13b.pdf
title: Clustered Support Vector Machines
abstract: In many problems of machine learning, the data are distributed nonlinearly.
  One way to address this kind of data is training a nonlinear classifier such as
  kernel support vector machine (kernel SVM). However, the computational burden of
  kernel SVM limits its application to large scale datasets. In this paper, we propose
  a Clustered Support Vector Machine (CSVM), which tackles the data in a divide and
  conquer manner. More specifically, CSVM groups the data into several clusters, followed
  which it trains a linear support vector machine in each cluster to separate the
  data locally. Meanwhile, CSVM has an additional global regularization, which requires
  the weight vector of each local linear SVM aligning with a global weight vector.
  The global regularization leverages the information from one cluster to another,
  and avoids over-fitting in each cluster. We derive a data-dependent generalization
  error bound for CSVM, which explains the advantage of CSVM over linear SVM. Experiments
  on several benchmark datasets show that the proposed method outperforms linear SVM
  and some other related locally linear classifiers. It is also comparable to a fine-tuned
  kernel SVM in terms of prediction performance, while it is more efficient than kernel
  SVM.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gu13b
month: 0
firstpage: 307
lastpage: 315
page: 307-315
sections: 
author:
- given: Quanquan
  family: Gu
- given: Jiawei
  family: Han
date: 2013-04-29
address: Scottsdale, Arizona, USA
publisher: PMLR
container-title: Proceedings of the Sixteenth International Conference on Artificial
  Intelligence and Statistics
volume: '31'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 4
  - 29
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
